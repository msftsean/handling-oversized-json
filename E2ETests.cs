using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Text.Json;
using System.Threading.Tasks;
using Contoso.AIFoundry.JsonProcessing;

namespace Contoso.AIFoundry.Tests
{
    /// <summary>
    /// End-to-end tests for the 5-step incident data processing pipeline.
    /// Tests all major use cases and validates output quality.
    /// 
    /// Test Categories:
    /// 1. Data Preprocessing & Filtering
    /// 2. Semantic Chunking Strategies
    /// 3. Token Budget Management
    /// 4. Orchestrator Workflow (with mock LLM responses)
    /// 5. Performance & Scalability
    /// 6. Error Handling & Edge Cases
    /// </summary>
    public class E2ETestRunner
    {
        private readonly string _outputDir;
        private List<TestResult> _results;

        public E2ETestRunner()
        {
            _outputDir = Path.Combine(Directory.GetCurrentDirectory(), "test_results");
            Directory.CreateDirectory(_outputDir);
            _results = new List<TestResult>();
        }

        public static async Task Main(string[] args)
        {
            Console.WriteLine("""
            â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
            â•‘            END-TO-END TEST SUITE FOR INCIDENT PROCESSING          â•‘
            â•‘                     5-Step LLM Processing Pipeline                 â•‘
            â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            """);

            var runner = new E2ETestRunner();
            await runner.RunAllTests();
            runner.PrintSummary();
        }

        private async Task RunAllTests()
        {
            Console.WriteLine("\nğŸ“‹ TEST SUITE EXECUTION\n" + new string('=', 70));

            // Category 1: Preprocessing Tests
            await Test_Preprocessing_FilteringRelevantFields();
            await Test_Preprocessing_RemovesVerboseData();
            await Test_Preprocessing_SizeReduction();
            await Test_Preprocessing_PreservesIncidentContext();

            // Category 2: Semantic Chunking Tests
            await Test_Chunking_SeverityBased();
            await Test_Chunking_LocationBased();
            await Test_Chunking_FixedSize();
            await Test_Chunking_TokenLimits();

            // Category 3: Token Management Tests
            await Test_TokenBudget_Validation();
            await Test_TokenBudget_CalculateCorrectly();
            await Test_TokenBudget_RejectOversized();

            // Category 4: Processing Pipeline Tests
            await Test_Pipeline_ContextVaryingPattern();
            await Test_Pipeline_AggregationAccuracy();
            await Test_Pipeline_MultipleUseCase();

            // Category 5: Performance Tests
            await Test_Performance_SupervisorDashboard();
            await Test_Performance_DispatcherQuery();
            await Test_Performance_LargeDataset();

            // Category 6: Edge Cases
            await Test_EdgeCase_EmptyDataset();
            await Test_EdgeCase_VeryLargeIncidents();
            await Test_EdgeCase_MixedSeverities();
        }

        // =====================================================================
        // CATEGORY 1: PREPROCESSING TESTS
        // =====================================================================

        private async Task Test_Preprocessing_FilteringRelevantFields()
        {
            var test = new TestResult("Preprocessing: Filter to Relevant Fields");

            try
            {
                var relevantFields = new[] { "incident_id", "severity_level", "location" };
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(relevantFields);

                var input = new Dictionary<string, object>
                {
                    { "incident_id", "INC-001" },
                    { "severity_level", "HIGH" },
                    { "location", "Downtown" },
                    { "internal_notes", "Should be removed" },
                    { "full_history", "Also removed" }
                };

                var records = new List<Dictionary<string, object>> { input };
                var filtered = preprocessor.FilterRecords(records);

                test.AssertEqual(filtered.Count, 1, "Should have 1 record");
                test.AssertEqual(filtered[0].Count, 3, "Should have only 3 fields");
                test.AssertTrue(filtered[0].ContainsKey("incident_id"), "Should contain incident_id");
                test.AssertTrue(!filtered[0].ContainsKey("internal_notes"), "Should not contain internal_notes");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Preprocessing_RemovesVerboseData()
        {
            var test = new TestResult("Preprocessing: Removes Verbose/Internal Data");

            try
            {
                var relevantFields = new[] { "incident_id", "event_timeline" };
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(relevantFields);

                var input = new Dictionary<string, object>
                {
                    { "incident_id", "INC-002" },
                    { "event_timeline", "Timeline data" },
                    { "internal_notes", string.Concat(Enumerable.Repeat("verbose ", 100)) },
                    { "attachments", new[] { "file1.pdf", "file2.jpg" } },
                    { "full_history", new object[] { "a", "b", "c" } }
                };

                var records = new List<Dictionary<string, object>> { input };
                var filtered = preprocessor.FilterRecords(records);

                test.AssertTrue(filtered[0].Count == 2, "Should remove all verbose fields");
                test.AssertTrue(!filtered[0].ContainsKey("internal_notes"), "Should not contain internal_notes");
                test.AssertTrue(!filtered[0].ContainsKey("attachments"), "Should not contain attachments");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Preprocessing_SizeReduction()
        {
            var test = new TestResult("Preprocessing: Achieves Size Reduction");

            try
            {
                var relevantFields = new[] { "incident_id", "severity_level" };
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(relevantFields);

                // Create incident with verbose data
                var incident = new Dictionary<string, object>
                {
                    { "incident_id", "INC-003" },
                    { "severity_level", "MEDIUM" },
                    { "verbose_field", string.Concat(Enumerable.Repeat("x", 1000)) },
                    { "large_array", Enumerable.Range(0, 500).ToArray() }
                };

                var originalSize = JsonSerializer.Serialize(incident).Length;
                
                var records = new List<Dictionary<string, object>> { incident };
                var filtered = preprocessor.FilterRecords(records);
                var reduction = preprocessor.CalculateReduction(originalSize, new[] { filtered });

                test.AssertTrue(reduction > 0.5, $"Should achieve >50% reduction, got {reduction:P}");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Preprocessing_PreservesIncidentContext()
        {
            var test = new TestResult("Preprocessing: Preserves Critical Incident Context");

            try
            {
                var relevantFields = new[] { "incident_id", "event_timeline", "severity_level" };
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(relevantFields);

                var incident = new Dictionary<string, object>
                {
                    { "incident_id", "INC-004" },
                    { "event_timeline", new[] { "14:30 - Call received", "14:38 - Units arrived" } },
                    { "severity_level", "HIGH" },
                    { "internal_notes", "Remove me" }
                };

                var records = new List<Dictionary<string, object>> { incident };
                var filtered = preprocessor.FilterRecords(records);

                test.AssertTrue(filtered[0].ContainsKey("event_timeline"), "Must preserve event_timeline");
                test.AssertEqual(
                    ((object[])filtered[0]["event_timeline"]).Length, 
                    2, 
                    "Must preserve all timeline events");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        // =====================================================================
        // CATEGORY 2: SEMANTIC CHUNKING TESTS
        // =====================================================================

        private async Task Test_Chunking_SeverityBased()
        {
            var test = new TestResult("Chunking: Severity-Based Grouping");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 5000);

                var incidents = new List<Dictionary<string, object>>();
                for (int i = 0; i < 10; i++)
                {
                    incidents.Add(new Dictionary<string, object>
                    {
                        { "incident_id", $"INC-{i:D3}" },
                        { "severity_level", i % 3 == 0 ? "HIGH" : (i % 3 == 1 ? "MEDIUM" : "LOW") },
                        { "description", $"Incident {i}" }
                    });
                }

                var chunks = chunker.ChunkBySeverity(incidents, i => i["severity_level"].ToString()).ToList();

                test.AssertTrue(chunks.Count > 0, "Should create chunks");
                test.AssertTrue(chunks.Count <= 3, "Should group by severity (max 3 groups)");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Chunking_LocationBased()
        {
            var test = new TestResult("Chunking: Location-Based Grouping");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 5000);

                var incidents = new List<Dictionary<string, object>>();
                var locations = new[] { "Downtown", "North", "South" };
                for (int i = 0; i < 15; i++)
                {
                    incidents.Add(new Dictionary<string, object>
                    {
                        { "incident_id", $"INC-{i:D3}" },
                        { "location", locations[i % 3] },
                        { "description", $"Incident at {locations[i % 3]}" }
                    });
                }

                var chunks = chunker.ChunkByLocation(incidents, i => i["location"].ToString()).ToList();

                test.AssertTrue(chunks.Count > 0, "Should create location-based chunks");
                test.AssertTrue(chunks.Count <= 3, "Should group by 3 locations");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Chunking_FixedSize()
        {
            var test = new TestResult("Chunking: Fixed-Size Chunking");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 4000);

                var incidents = new List<Dictionary<string, object>>();
                for (int i = 0; i < 100; i++)
                {
                    incidents.Add(new Dictionary<string, object>
                    {
                        { "incident_id", $"INC-{i:D5}" },
                        { "data", new string('x', 50) }
                    });
                }

                var chunks = chunker.ChunkFixedSize(incidents, chunkSize: 10).ToList();

                test.AssertTrue(chunks.Count == 10, $"Should create 10 chunks (100 incidents, size 10), got {chunks.Count}");
                test.AssertTrue(chunks.All(c => c.Count <= 10), "All chunks should be <= 10 items");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Chunking_TokenLimits()
        {
            var test = new TestResult("Chunking: Respects Token Limits");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 3000);

                var incidents = new List<Dictionary<string, object>>();
                for (int i = 0; i < 50; i++)
                {
                    incidents.Add(new Dictionary<string, object>
                    {
                        { "incident_id", $"INC-{i:D5}" },
                        { "large_text", string.Concat(Enumerable.Repeat("incident data ", 20)) }
                    });
                }

                var chunks = chunker.ChunkFixedSize(incidents, chunkSize: 20).ToList();

                foreach (var chunk in chunks)
                {
                    var chunkJson = JsonSerializer.Serialize(chunk);
                    var estimatedTokens = tokenCounter.EstimateTokenCount(chunkJson);
                    test.AssertTrue(estimatedTokens <= 3500, $"Chunk exceeds limit: {estimatedTokens} tokens");
                }

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        // =====================================================================
        // CATEGORY 3: TOKEN MANAGEMENT TESTS
        // =====================================================================

        private async Task Test_TokenBudget_Validation()
        {
            var test = new TestResult("Token Budget: Validates Request Before LLM");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var manager = new TokenBudgetManager(tokenCounter);

                var smallRequest = "Analyze this: " + string.Concat(Enumerable.Repeat("data ", 100));
                var validation = manager.ValidateTokenBudget(smallRequest, promptTokenBudget: 8000, outputTokenBudget: 2000);

                test.AssertTrue(validation.IsValid, "Small request should be valid");
                test.AssertTrue(validation.TotalTokensEstimate < 8000, "Should estimate < 8000 tokens");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_TokenBudget_CalculateCorrectly()
        {
            var test = new TestResult("Token Budget: Calculates Token Count Accurately");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var text1 = "Hello world";
                var text2 = "Hello world Hello world Hello world Hello world";

                var tokens1 = tokenCounter.EstimateTokenCount(text1);
                var tokens2 = tokenCounter.EstimateTokenCount(text2);

                test.AssertTrue(tokens1 > 0, "Should estimate tokens for text1");
                test.AssertTrue(tokens2 > tokens1, "Longer text should have more tokens");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_TokenBudget_RejectOversized()
        {
            var test = new TestResult("Token Budget: Rejects Oversized Requests");

            try
            {
                var tokenCounter = new ApproximateTokenCounter();
                var manager = new TokenBudgetManager(tokenCounter);

                // Create a very large request
                var largeRequest = string.Concat(Enumerable.Repeat("data ", 10000));
                var validation = manager.ValidateTokenBudget(largeRequest, promptTokenBudget: 5000, outputTokenBudget: 1000);

                test.AssertTrue(!validation.IsValid, "Large request should be rejected");
                test.AssertTrue(!string.IsNullOrEmpty(validation.ErrorMessage), "Should provide error message");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        // =====================================================================
        // CATEGORY 4: PROCESSING PIPELINE TESTS
        // =====================================================================

        private async Task Test_Pipeline_ContextVaryingPattern()
        {
            var test = new TestResult("Pipeline: Context-Varying Pattern Preserves Context");

            try
            {
                // Simulate context-varying pattern
                var incidents = GenerateIncidents(30);
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 5000);
                var chunks = chunker.ChunkFixedSize(incidents, chunkSize: 10).ToList();

                // Verify context is available from previous chunk
                var previousContext = "";
                var contextPreservation = 0;

                foreach (var chunk in chunks)
                {
                    // In real execution, previousContext would be the summary from previous chunk
                    if (!string.IsNullOrEmpty(previousContext))
                    {
                        contextPreservation++;
                    }
                    previousContext = $"Chunk summary: {string.Join(",", chunk.Select(i => i["incident_id"]))}";
                }

                test.AssertTrue(contextPreservation > 0, "Context should be preserved between chunks");
                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Pipeline_AggregationAccuracy()
        {
            var test = new TestResult("Pipeline: Aggregation Combines Results Accurately");

            try
            {
                // Create mock analysis results
                var results = new List<(List<string> highPriority, List<string> mediumPriority, List<string> recommendations)>
                {
                    (new List<string> { "Issue1", "Issue2" }, new List<string> { "Issue3" }, new List<string> { "Rec1" }),
                    (new List<string> { "Issue4" }, new List<string> { "Issue5", "Issue6" }, new List<string> { "Rec2", "Rec3" }),
                    (new List<string> { }, new List<string> { "Issue7" }, new List<string> { "Rec4" })
                };

                // Aggregate
                var totalHigh = results.Sum(r => r.highPriority.Count);
                var totalMedium = results.Sum(r => r.mediumPriority.Count);
                var totalRecs = results.Sum(r => r.recommendations.Count);

                test.AssertEqual(totalHigh, 3, "Should have 3 high priority issues");
                test.AssertEqual(totalMedium, 4, "Should have 4 medium priority issues");
                test.AssertEqual(totalRecs, 4, "Should have 4 total recommendations");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Pipeline_MultipleUseCase()
        {
            var test = new TestResult("Pipeline: Supports Multiple Use Cases");

            try
            {
                var incidents = GenerateIncidents(50);

                // Use case 1: Supervisor dashboard (high priority only)
                var dashboardIncidents = incidents.Where(i => i["severity_level"].ToString() == "HIGH").Take(20).ToList();
                test.AssertTrue(dashboardIncidents.Count > 0, "Should filter high priority for dashboard");

                // Use case 2: Dispatcher context (location based)
                var dispatcherIncidents = incidents.Where(i => i["location"].ToString() == "Downtown").ToList();
                test.AssertTrue(dispatcherIncidents.Count > 0, "Should filter by location for dispatcher");

                // Use case 3: Compliance (all incidents with context)
                test.AssertEqual(incidents.Count, 50, "Should process all incidents for compliance");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        // =====================================================================
        // CATEGORY 5: PERFORMANCE TESTS
        // =====================================================================

        private async Task Test_Performance_SupervisorDashboard()
        {
            var test = new TestResult("Performance: Supervisor Dashboard < 2 seconds");

            try
            {
                var sw = Stopwatch.StartNew();
                var incidents = GenerateIncidents(50).Where(i => i["severity_level"].ToString() == "HIGH").ToList();
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(new[] { "incident_id", "severity_level" });
                var filtered = preprocessor.FilterRecords(incidents);
                sw.Stop();

                test.AssertTrue(sw.ElapsedMilliseconds < 2000, 
                    $"Supervisor dashboard should be < 2 seconds, took {sw.ElapsedMilliseconds}ms");
                test.Metrics = $"Processed {filtered.Count} incidents in {sw.ElapsedMilliseconds}ms";

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Performance_DispatcherQuery()
        {
            var test = new TestResult("Performance: Dispatcher Query < 3 seconds");

            try
            {
                var sw = Stopwatch.StartNew();
                var incidents = GenerateIncidents(100).Where(i => i["location"].ToString() == "Downtown").ToList();
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 8000);
                var chunks = chunker.ChunkFixedSize(incidents, chunkSize: 20).ToList();
                sw.Stop();

                test.AssertTrue(sw.ElapsedMilliseconds < 3000,
                    $"Dispatcher query should be < 3 seconds, took {sw.ElapsedMilliseconds}ms");
                test.Metrics = $"Created {chunks.Count} chunks in {sw.ElapsedMilliseconds}ms";

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_Performance_LargeDataset()
        {
            var test = new TestResult("Performance: Large Dataset (500 incidents) < 30 seconds");

            try
            {
                var sw = Stopwatch.StartNew();
                var incidents = GenerateIncidents(500);
                var relevantFields = new[] { "incident_id", "severity_level", "location", "event_timeline" };
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(relevantFields);
                var filtered = preprocessor.FilterRecords(incidents);
                
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 8000);
                var chunks = chunker.ChunkFixedSize(filtered, chunkSize: 50).ToList();
                sw.Stop();

                test.AssertTrue(sw.ElapsedMilliseconds < 30000,
                    $"Large dataset should process < 30 seconds, took {sw.ElapsedMilliseconds}ms");
                test.Metrics = $"Processed 500 incidents into {chunks.Count} chunks in {sw.ElapsedMilliseconds}ms";

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        // =====================================================================
        // CATEGORY 6: EDGE CASE TESTS
        // =====================================================================

        private async Task Test_EdgeCase_EmptyDataset()
        {
            var test = new TestResult("Edge Case: Handles Empty Dataset");

            try
            {
                var incidents = new List<Dictionary<string, object>>();
                var preprocessor = new JsonPreprocessor<Dictionary<string, object>>(new[] { "incident_id" });
                var filtered = preprocessor.FilterRecords(incidents);

                test.AssertEqual(filtered.Count, 0, "Should handle empty dataset gracefully");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_EdgeCase_VeryLargeIncidents()
        {
            var test = new TestResult("Edge Case: Handles Very Large Individual Incidents");

            try
            {
                var incident = new Dictionary<string, object>
                {
                    { "incident_id", "INC-LARGE" },
                    { "event_timeline", string.Concat(Enumerable.Repeat("Event ", 1000)) },
                    { "description", string.Concat(Enumerable.Repeat("x", 5000)) }
                };

                var incidents = new List<Dictionary<string, object>> { incident };
                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 8000);
                var chunks = chunker.ChunkFixedSize(incidents, chunkSize: 1).ToList();

                test.AssertTrue(chunks.Count > 0, "Should handle large incidents");
                test.AssertTrue(chunks[0].Count == 1, "Should contain the large incident");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        private async Task Test_EdgeCase_MixedSeverities()
        {
            var test = new TestResult("Edge Case: Handles Mixed Severity Levels");

            try
            {
                var incidents = new List<Dictionary<string, object>>();
                var severities = new[] { "CRITICAL", "HIGH", "MEDIUM", "LOW", "INFO" };

                for (int i = 0; i < 50; i++)
                {
                    incidents.Add(new Dictionary<string, object>
                    {
                        { "incident_id", $"INC-{i:D3}" },
                        { "severity_level", severities[i % severities.Length] }
                    });
                }

                var tokenCounter = new ApproximateTokenCounter();
                var chunker = new SemanticChunker(tokenCounter, maxChunkTokens: 8000);
                var chunks = chunker.ChunkBySeverity(incidents, i => i["severity_level"].ToString()).ToList();

                test.AssertTrue(chunks.Count > 0, "Should create chunks with mixed severities");
                test.AssertTrue(chunks.Count <= 5, "Should group into at most 5 severity buckets");

                test.Status = TestStatus.Passed;
            }
            catch (Exception ex)
            {
                test.Status = TestStatus.Failed;
                test.ErrorMessage = ex.Message;
            }

            _results.Add(test);
            PrintTestResult(test);
            await Task.CompletedTask;
        }

        // =====================================================================
        // HELPER METHODS
        // =====================================================================

        private List<Dictionary<string, object>> GenerateIncidents(int count)
        {
            var incidents = new List<Dictionary<string, object>>();
            var severities = new[] { "HIGH", "MEDIUM", "LOW" };
            var locations = new[] { "Downtown", "North", "South", "East", "West" };
            var types = new[] { "Structure Fire", "Vehicle Accident", "Medical Emergency" };

            for (int i = 0; i < count; i++)
            {
                incidents.Add(new Dictionary<string, object>
                {
                    { "incident_id", $"INC-{i:D5}" },
                    { "incident_type", types[i % types.Length] },
                    { "severity_level", severities[i % severities.Length] },
                    { "location", locations[i % locations.Length] },
                    { "event_timeline", new[] { "14:30 - Call received", "14:38 - Units arrived" } },
                    { "dispatch_time", "2024-11-19T14:30:00Z" },
                    { "assigned_units", new[] { $"Unit-{i % 10}", $"Unit-{(i + 1) % 10}" } },
                    { "hazmat_flag", i % 15 == 0 },
                    { "internal_notes", string.Concat(Enumerable.Repeat("Internal ", 50)) },
                    { "verbose_data", string.Concat(Enumerable.Repeat("x", 500)) }
                });
            }

            return incidents;
        }

        private void PrintTestResult(TestResult result)
        {
            var statusIcon = result.Status == TestStatus.Passed ? "âœ“" : "âœ—";
            var statusColor = result.Status == TestStatus.Passed ? "\x1b[32m" : "\x1b[31m";
            var reset = "\x1b[0m";

            Console.WriteLine($"{statusColor}[{statusIcon}]{reset} {result.Name}");
            if (!string.IsNullOrEmpty(result.Metrics))
            {
                Console.WriteLine($"    Metrics: {result.Metrics}");
            }
            if (result.Status == TestStatus.Failed && !string.IsNullOrEmpty(result.ErrorMessage))
            {
                Console.WriteLine($"    Error: {result.ErrorMessage}");
            }
        }

        private void PrintSummary()
        {
            Console.WriteLine("\n" + new string('=', 70));
            Console.WriteLine("TEST SUMMARY");
            Console.WriteLine(new string('=', 70));

            var passed = _results.Count(r => r.Status == TestStatus.Passed);
            var failed = _results.Count(r => r.Status == TestStatus.Failed);
            var total = _results.Count;

            Console.WriteLine($"\nTotal Tests: {total}");
            Console.WriteLine($"âœ“ Passed: {passed} ({(100.0 * passed / total):F1}%)");
            Console.WriteLine($"âœ— Failed: {failed} ({(100.0 * failed / total):F1}%)");

            if (failed > 0)
            {
                Console.WriteLine($"\nFailed Tests:");
                foreach (var result in _results.Where(r => r.Status == TestStatus.Failed))
                {
                    Console.WriteLine($"  - {result.Name}: {result.ErrorMessage}");
                }
            }

            // Save results to file
            var reportPath = Path.Combine(_outputDir, $"test_results_{DateTime.Now:yyyyMMdd_HHmmss}.txt");
            using (var writer = new StreamWriter(reportPath))
            {
                writer.WriteLine($"Test Results - {DateTime.Now:yyyy-MM-dd HH:mm:ss}");
                writer.WriteLine(new string('=', 70));
                writer.WriteLine($"Total: {total} | Passed: {passed} | Failed: {failed}");
                writer.WriteLine();

                foreach (var result in _results)
                {
                    writer.WriteLine($"[{result.Status}] {result.Name}");
                    if (!string.IsNullOrEmpty(result.Metrics))
                    {
                        writer.WriteLine($"  Metrics: {result.Metrics}");
                    }
                    if (!string.IsNullOrEmpty(result.ErrorMessage))
                    {
                        writer.WriteLine($"  Error: {result.ErrorMessage}");
                    }
                }
            }

            Console.WriteLine($"\nâœ“ Results saved to: {reportPath}");

            // Print success summary
            if (failed == 0)
            {
                Console.WriteLine("""

                â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                â•‘                    ALL TESTS PASSED âœ“                             â•‘
                â•‘              Ready for customer demonstration                      â•‘
                â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                """);
            }
        }
    }

    // =========================================================================
    // TEST DATA STRUCTURES
    // =========================================================================

    public enum TestStatus
    {
        Passed,
        Failed
    }

    public class TestResult
    {
        public string Name { get; set; }
        public TestStatus Status { get; set; }
        public string ErrorMessage { get; set; }
        public string Metrics { get; set; }

        public TestResult(string name)
        {
            Name = name;
            Status = TestStatus.Failed;
        }

        public void AssertEqual<T>(T actual, T expected, string message)
        {
            if (!EqualityComparer<T>.Default.Equals(actual, expected))
            {
                throw new Exception($"{message} | Expected: {expected}, Got: {actual}");
            }
        }

        public void AssertTrue(bool condition, string message)
        {
            if (!condition)
            {
                throw new Exception(message);
            }
        }

        public void AssertFalse(bool condition, string message)
        {
            if (condition)
            {
                throw new Exception(message);
            }
        }
    }
}
